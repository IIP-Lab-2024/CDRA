# From Bias To Fairness

It is divided into two files, one for training the model and one for testing the model

Create two separate folders to save and download the corresponding dependencies

### train model: CDA + LoRA

Please install LMFLOW framework, specific installation please refer to the file: https://github.com/OptimalScale/LMFlow

After the installation is complete, perform the following operations:

##### 1. Insert the file

Add the following two files to the LMFLOW scripts:

**"train_model/scripts/create_cda_data.sh" "train_model/scripts/run_finetune_with_lora_save_aggregated_weights_cda.sh"**



Add the following file to the examples in LMFLOW:
**"train_model/examples/cda_augments_data.py"**



Add the following file to the LMFLOW. The specific address can be added to the lmflow/data/text/

**"train_model/data\text/wikipedia-10.txt.zip"**

# # # # #



##### 2. Run the script

###### unzip the original data set for cda

`unzip lmflow/data/text/wikipedia-10.txt.zip`

###### cda

To generate counterfactual data first, run the following command in the LMflow directory:
`bash scripts/create_cda_data.sh`

The script takes two parameters, the save address of the generated dataset and the address of the original dataset used for cda

` ` `
--save-path "data/cda_data/"
--ori-data-path "data/text/wikipedia-10.txt"
` ` `

###### LoRA

The next step is to use the cda dataset to fine-tune the model by running the following command in the LMflow directory

`bash scripts/run_finetune_with_lora_save_aggregated_weights_cda.sh`

The script has the following parameters. Modify them as required

` ` `
bias_types=('gender' 'race' 'religion')
model_name_or_path="/date1/zwx/bias-bench-main/gpt2" address of the fine-tuned model
deepspeed_args="--master_port=10004" Indicates the communication port number
steps Indicates the length of the training data
dataset_path Indicates the address of the dataset generated by cda
output_dir Output address of the trained model

Other parameters can be modified according to the actual situation
` ` `



### test model: bias-bench-main

Dependent download [If there is no dependency, download the latest one directly] :

` ` `
The torch = = 2.0.0
Transformers = = 4.31.0
Scipy = = 1.7.3
Scikit - learn = = 1.0.2
Me = = 3.7.0
Datasets = = 1.18.3
Accelerate the = = 0.24.1
Deepspeed = = 0.10.0
Numpy = = 1.22.4
TQDM = = 4.66.1
` ` `



Before testing the model, modify the parameters of each script in batch_jobs to suit your actual situation

Describes the scripts used in ##### bath_jobs

The parameters of each script need to be modified. Modify the parameters according to the actual addresses of your fine-tuning model and the original model

_experiment_configuration.sh contains bias categories, main file address ** [need to be modified to own file directory] **, model name mapping, etc

Seate.sh tests the degree of bias of the original model in the SEAT dataset

seat_debias.sh tests the degree of bias of the fine-tuned model in the SEAT dataset

crows.sh tests the degree of bias of the original model in the SEAT dataset

crows_debias.sh tests the degree of bias of the fine-tuned model in the Crows Pairs dataset

Stereoset.sh tests the degree of bias of the original model in the stereoset data set

stereoset_debias.sh tests the degree of bias of the fine-tuned model in the stereoset data set

stereoset_to_json.sh converts the results of the model testing on the stereoset dataset into json format

##### Script running sequence:

Change the parameter in _experiment_configuration.sh to your own, such as persistent_dir

Then you can execute the individual test set scripts [** Please modify the parameters of each script according to the actual situation **], for example

`bash batch_jobs/seat.sh`

`bash batch_jobs/seat_debias.sh`

`bash batch_jobs/crows.sh`

`bash batch_jobs/crows_debias.sh`

`bash batch_jobs/stereoset.sh`

`bash batch_jobs/stereoset_debias.sh`

`bash batch_jobs/stereoset_to_json.sh`

** Precautions **

For scripts that test the raw model, the model loads mainly with the parameter **model_name_or_path**

For scripts that test the fine-tuning model, the model is mainly loaded by the parameter **load_path**
